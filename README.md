# ðŸŽˆ Blank app template

A simple Streamlit app template for you to modify!

[![Open in Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://blank-app-template.streamlit.app/)

### How to run it on your own machine

1. Install the requirements

   ```
   $ pip install -r requirements.txt
   ```

2. Run the app

   ```
   $ streamlit run streamlit_app.py
   ```
##1. Mounting Google Drive and Importing Libraries:

The code starts by mounting your Google Drive to access the dataset stored there.
Then, it imports necessary libraries for data manipulation (pandas), machine learning (scikit-learn, TensorFlow, Keras), visualization (matplotlib, seaborn), and model saving (joblib).
##2. Uploading and Preprocessing the Dataset:

The code loads the dataset from your Google Drive using pd.read_excel().
It displays the first few rows using data_import.head() to get an idea of the data.
It identifies and drops unimportant features based on domain knowledge (e.g., 'Study Hours').
It converts categorical features (e.g., 'Sex', 'HighSchool') into numerical values using label encoding with LabelEncoder(). This is necessary for the RNN model to understand these features.
It performs Exploratory Data Analysis (EDA) using sns.pairplot() to visualize relationships between features.
##3. Data Splitting and Feature Scaling:

The code separates the target variable ('GRADE') from the features using X = data_import.drop(columns=['GRADE']) and y = data_import['GRADE'].
It splits the data into training and testing sets using train_test_split() for model evaluation.
It reshapes the training and testing features into a format suitable for RNNs using np.reshape(). RNNs expect features to be sequences, hence the 3D shape (samples, timesteps, features).
It standardizes the features using StandardScaler() to ensure all features are on a similar scale, which can improve model performance. The scaler is then saved for later use when making predictions on new data.
##4. Defining and Training the RNN Model:

The code defines a Sequential model using Sequential().
It adds a SimpleRNN layer with 50 units and 'relu' activation for processing sequential data.
Dropout (with a rate of 20%) is added for regularization to prevent overfitting.
A Dense layer with 30 units and 'relu' activation is added for further feature extraction.
Finally, a Dense layer with 8 units and 'softmax' activation is added for multi-class classification (predicting one of 8 possible grades).
An optimizer (Adam with an exponential learning rate decay) and loss function ('sparse_categorical_crossentropy') are defined for training the model.
Early stopping is implemented using EarlyStopping() to stop training if the validation loss doesn't improve for a certain number of epochs (patience=3), preventing overfitting.
The model is trained using model.fit() with the training data, epochs (number of training iterations), batch size, validation split (portion of training data used for monitoring), and verbosity level.
##5. Evaluating the Model:

The code plots the training and validation loss/accuracy curves using matplotlib.pyplot to visualize the model's learning progress.
It evaluates the model's performance on the testing set using model.evaluate() and prints the test loss and accuracy.
It generates classification report and confusion matrix using classification_report() and confusion_matrix() to assess the model's performance on each grade category.
## 6. Saving the Model and Scaler:

The trained model is saved using joblib.dump() for future use in making predictions on new data.
The scaler used for feature standardization is also saved for later use when making predictions on new data that needs to be scaled in the same way as the training data.
Overall, this code demonstrates a well-structured approach to building and evaluating an RNN for student grade prediction in Google Colab.

Project Summary
Project Goal: Predict student letter grades based on non-traditional factors such as age, sex, relationship status, and parental status, rather than solely focusing on academic performance.

Data: The project utilized a dataset from the UCI Machine Learning Repository containing information about students, including both academic and non-academic attributes.

Methodology:

Data Preprocessing: Dropped academic-related features, encoded categorical variables, and explored data distribution.
Model Development: Built a Recurrent Neural Network (RNN) model with a SimpleRNN layer, dropout, and dense layers.
Model Training: Trained the model using early stopping to prevent overfitting.
Model Evaluation: Evaluated the model's performance using metrics like accuracy, loss, precision, recall, and F1-score.
Results: The model achieved an accuracy of 95% and demonstrated strong performance across different evaluation metrics.

Conclusion: The project successfully demonstrated the potential of using non-traditional factors to predict student grades. Further research could explore the impact of different RNN architectures and hyperparameter tuning on model performance.
